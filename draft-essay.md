# Introduction

Artificial Intelligence or AI is, in very basic terms, the ability of a computer program or machine to think and learn.

It has also been described as a "systems ability to correctly interpret external data and use those learnings to achieve specific goals and tasks through flexible adaptation". This more detailed definition shows the core principles of AI by referencing its adaptation to show how it is a very flexible technology and the wording of "specific goals and tasks" shows how Artificial Intelligence is supposed to be integrated into a system in such a way that it isn't having to guess about the correct outcome too much.

In the current technology market, Artificial Intelligence seems to be being pushed to the forefront of the advancement of modern technology.
On the surface, the extraordinary ability of AI in handling and processing large amounts of incoming data in a short space of time in order to come to a decision, makes a lot of sense when thinking about where to apply this in everyday workloads. On the other hand, in order for AI to function at its peak efficiency, there has to be that large amount of data available to process in the first place otherwise the technology is not being applied in the most optimum way.
Trying to find the right balance between applying AI in consumer devices and not wasting resources on developing an unnecessarily complicated way of solving basic problems. Now that the market has decided to begin adding AI to as many devices as possible, ranging from fridges and light fixtures to robotic vacuum cleaners and smartphones, it begs the question, "Is the introduction of Artificial Intelligence into every consumer electronic device actually beneficial to the way the devices function and are used by the consumer or is it just another marketing buzzword and gimmick to help designers and manufactures sell as many of their gadgets and gizmos as they can to try and turn the largest profit?"

# Hardware enabled AI devices
## Huawei Mate 10 Pro
One consumer device that utilises hardware based AI is the Huawei Mate 10 Pro smartphone.
To power the AI, it uses a uses a Neural Processing Unit (NPU) built into its chipset, the Kirin 970, which also contains the CPU (Central Processing Unit) and IGP/GPU (Integrated Graphics Processor/Graphics Processing Unit).
An NPU is designed with artificial intelligence in mind which means it is much more powerful in AI tasks than the CPU's and GPU's that were available at the time of launch.
The main marketing point for the AI in this phone is the smart camera adjustments based on what the sensor is being pointed at. The phone uses the NPU to adjust settings in the camera app by analysing the image to correct exposure and focus in order to improve the photo being taken.
By the means of AI powered object recognition, the NPU has the ability to easily recognise the subject of the photo and make adjustments in order to make the photo look better. To give an example, if the phone recognises food being in front of the camera, it begin to up the contrast and saturation up to a certain point which is also calculated by the AI, to make the dish look more appealing and if animals are recognised, the AI knows that it should focus on the fine details of the creature which will make the shot crisper and appear more true to life.
The NPU also has the ability be used to identify the subject of a portrait style photo and apply a bokeh depth of field effect to the image, which keeps the person in focus and makes the background blurry. By using the AI, the phone can do a lot of the processing after the image has been taken by retro actively identifying the edges of the subject and blurring the outside.

The second main use that is targeted towards the consumer is the use of the NPU to manage resources more efficiently. This means it can keep the phone cool whilst charging to protect the battery and give it a longer life. By managing the resources properly, it can also prioritise foreground processes which will make the phone feel snappier to the user.
The NPU is also utilised in translation because of its power when analysing large amounts of data to gather more from context when there are multiple translations of a word so that a more understandable translation is produced.

The main advantage of AI in this smartphone is improving the user experience. Being able to automatically adjust the camera to take better photos is a huge selling point and is one that the user will be able to appreciate when their photos come out sharper and better looking than with the use of AI. The other main advantage is the perceived increase in performance from the better resource management. Whether it's the increased responsiveness from dynamically preventing background processes from hogging the system resources and slowing down the foreground processes or whether it's the battery maintaining its peak capacity for longer so the user doesn't notice a reduction in on battery usage time over the life span of the phone, the the more average user is going to notice these improvements without having to have much knowledge of how the device works.

The main disadvantage is the price. At launch, it cost £699 which is quite expensive considering it only has 6GB of RAM and 128GB of internal storage. Many similar brands like OnePlus and other chinese phone manufacturers are offering higher specced devices including twice the internal storage for over £100 less. This means that the NPU aspect of the chipset is either very expensive to design and manufacture or that the addition of the NPU is an excuse to bump the price and increase the profit margins.

## Nvidia Turing Graphics Cards

The second implementation of artificial intelligence hardware in a mainstream consumer product is the addition of Tensor cores as part of the latest graphics processing unit (GPU) architecture, code named "Turing" after the famous British computer scientist and cryptoanalyst Alan Turing, from Nvidia, who have the largest market share for discrete graphics. As this is the first time a GPU has been designed with specialised hardware for AI, the number of Tensor cores is contributes to a small amount of the total processing power of the GPU but as it is just an extra addition rather than the main reason for buying the card, it will not make too much difference to the consumer.
With the new addition of the Tensor cores as well as some other new technologies that are being sold to the public for the first time, the price for these new generation of GPUs is much higher than previous ones but this is quite normal and is considered a sort of early adopter tax for these new technologies.

The main use for the Tensor cores in the Turing architecture is to power an AI dedicated to applying a new type of anti aliasing to the graphics in video games. Anti aliasing is a form of post processing designed to smooth out jagged edges from horizontal lines. The AI can be used to inspect the image to identify the edges and then focus the anti aliasing processing on those areas to reduce the load or improve the quality.
Nvidia uses very powerful supercomputers in their server farms to inspect hours and hours of gameplay, and by comparing the differences between un aliased and perfectly aliased frames to teach an AI what to focus on to improve the effect of DLSS. The trained AI's are released to the public through driver updates so that the DLSS technique is always improving for supported games.
Another use for the Tensor cores is for rapid development and training of an AI that is being made by someone who doesn't have access to the same level of servers that large companies with large budgets do. By integrating the Tensor cores onto a graphics card means that a high power workstation can have access to this technology without spending extra on a dedicated Tensor core expansion card.

The main advantage of this addition to a consumer graphics card is the better allocation of resources. The graphics card can now use more of its main 3D compute power for the rendering of the main graphics and can offload the anti aliasing to the Tensor cores. As some of the main 3D graphics cores are no longer being used for the post processing effects like anti aliasing, the main graphics rendering has more resources to be powered by therefore, it can run at higher resolutions or frame rates without having to turn off any other effects.
Another advantage is that the additional Tensor cores allow the graphics card to be better utilised in the development and creation of new artificial intelligences by smaller developers. The Tensor cores

One drawback of the way Nvidia is distributing DLSS is that it only works on a game by game basis meaning that if a game has not been analysed in Nvidia's supercomputer, the DLSS is unlikely to work and, if it does work, the effect is going to be less noticeable to the user. However, this drawback is more about the delivery of the trained AI rather than a criticism of putting the dedicated hardware on the card.

# Software/cloud based AI

Some artificial intelligences are not powered by the device they appear to be running on and are instead usually based in "the cloud" or on a server in a large data center somewhere else in the world and the client device sends commands to the servers AI so that it can respond.

Common applications of these cloud AI's are in low power voice interactive speakers such as the Amazon Echo line up and Google Home products. These smart speakers have basic commands for various activities including:
* music playback,
* making to do lists,
* setting alarms,
* streaming podcasts,
* playing audiobooks,
* providing weather, traffic, sports and news
* searching the web for information and reading out the results



Another place a cloud based AI is likely to be found is on a smartphone in the form of a "virtual assistant". These can usually do the same things as a smart speaker with many more commands available with the addition of a screen and a sim card. These additions include:
* opening applications
* playing movies and tv shows through popular media streaming sites
* plan routes with directions for navigation
* sending texts and starting calls.

One of the features offered by Googles Virtual Assistant is an ability to make phone calls on behalf of the user named Google Duplex. Currently, the main applications of an automated assistant that can make phone calls are to book appointments at places like the doctors office, to place a reservations at a restaurants, or the book a room at a hotel.
The assistant uses AI for vocal recognition to work out what the person on the other end said and to say a good response based on the last thing that was said.
Other thing the AI is utilised for in the process of making the automated calls is speech fluency. Duplex introduces "speech disfluencies" into its computer generated speech to make the voice sound less robotic and to help the conversation flow with more fluidity. "Speech disfluencies" are small vocal breaks in the flow of an individual sentence. These vocal breaks are usually a type of non-verbal, vocal sounds such as "um" and "err" to cover when the brain takes a bit longer to formulate a word and sounds like "mm-hmm" to show acknowledgement of the last sentence when a suitable word or phrase isn't available.


One advantage of using a cloud based AI service is that the provider can have as much processing power dedicated to the AI as they need since they are not restricted by the space limitations of a modern smartphone or smart speaker. This means that the AI can become more and more complex based on the needs of the provider and their users whilst still being accessible to those who are not using the latest and most powerful client devices as the system requirements to run the user interface are often quite low.

One disadvantage of running the AI on a seperate device is that the providers of the AI services and deliver parts or all of the functionality as a monthly subscription despite the AI being advertised as being "built in" to the client device.

## comparisons

### costs of hardware vs cloud-Based ai

One of the main comparison points between hardware enabled Artificial Intelligence and Cloud based Artificial Intelligence is that of cost.
With hardware enabled AI, the main cost is usually a one time purchase of the hardware device that has the processing cores for the AI. On one hand, the one off cost of the hardware is good since it guarantees the availability of the AI processing benefits whilst the hardware is functional. On the other hand, the one time purchase is of hardware that will, almost certainly, become outdated with new products being launched, with typically generational improvements to the hardware, and eventually, the hardware that was purchased will need to be replaced to keep up with the power the AI requires for large amounts of data to be processed or the speed requirements that the user or users clients have for the training of the AI. As the hardware will have to be regularly replaced, the large payments at the time of each purchase of a piece of hardware to power the AI will add up over time to a much bigger sum.

With cloud-based AI, the client devices are usually of lower cost, such as a smart speaker which costs in the range of £30-100, but the usability of the AI is more locked down with the voice commands having to be pre-programmed by the providers of the cloud infrastructure that runs the AI. Some providers, such as Amazon with their Alexa AI, let more advanced users develop their own commands and processes that could be accessed from the voice interface but some providers don't let users do this and if they do, there is often a cost associated with hosting your own commands on their servers meaning that if any custom AI processes are needed, the monthly costs add up for each new action that the user makes.

One of the main applications of these cloud-based AI's in consumer homes is integration with smart home devices such as light fixtures and smart tvs through a process called If This Then That (IFTTT). When a company wants to interface between their product and a smart home, they have to build the circuits and software to run them into the product itself. Usually, the company will also have the product connect to their servers to makes sure the software is up to date and has all the latest security patches to prevent backdoor access into the users home network. However, this not always free. Many companies charge a monthly fee to add IFTTT integration for their new device into their existing smart home environment and if a user is connecting most of the devices in their home that can be smart-enabled, then the many monthly fees can grow into a very large sum being paid each month.



## conclusion
